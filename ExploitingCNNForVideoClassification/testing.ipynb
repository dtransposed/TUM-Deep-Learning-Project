{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing a couple of imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "import PretrainedCNN\n",
    "import VideoPooling as VP\n",
    "import PredictionHead as PH\n",
    "import VideoDataLoader as VDL\n",
    "import DataPreprocessing as DP\n",
    "#from solver import Solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path to datasets. Identifies the toplevel folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_small = r'C:\\Users\\Janis\\FinalDeepLearningProject\\TUM_DeepLearningProject-master\\datasets\\Frames_for _Damian\\Frames_for _Damian_small'\n",
    "path = r'C:\\Users\\Janis\\FinalDeepLearningProject\\TUM_DeepLearningProject-master\\datasets\\Frames_for _Damian\\Frames_for _Damian'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the video data into dictionary data. \n",
    "The dictionary has three entries:\n",
    "    data['data']  -> torch.FloatTensor with video frames\n",
    "    data['targets'] -> np array with classes\n",
    "    data['video_frames'] -> np array with number of frames belonging to each video\n",
    ". If we already loaded the pictures, normalized them and stored them in a pickle file, we can load it form the pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = VDL.load_videos(path, resize_images=True)\n",
    "#data = pickle.load(open('data_small_norm_56.p','rb'))\n",
    "data = pickle.load(open('data_norm_56.p','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The following two steps just need to be exucted if the data is loaded for the first time. Normalize data -> zero mean, std = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['data'] = DP.normalize(data['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dump the result in a pickle file for later usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(data, open('data_norm_56.p','wb') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run all the training example through the CNN and apply a pooling strategy for receiving a video representation. Due to memory issues, we store the result in a pickle file after every 5 trainingexamples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Number of traning examples\n",
    "N = data['targets'].shape[0]\n",
    "\n",
    "#Customized dataloader. \n",
    "batchloader = VDL.iterate_videos(data)\n",
    "\n",
    "#Get fully convolutional network for feature extraction on frame level\n",
    "pretrained_model = PretrainedCNN.Fully_Conv_Block('vgg11')\n",
    "\n",
    "#Check whether cua is available and utilize if possible\n",
    "if torch.cuda.is_available():\n",
    "    pretrained_model.cuda()\n",
    "\n",
    "#Some funny starting signal\n",
    "print('gOooo o_O O_o')\n",
    "\n",
    "#iterate over training examples\n",
    "for i in range(0,N):\n",
    "    \n",
    "    #store out of convolutional network after every five examples\n",
    "    #and dump the variable. This is done to prevent OutOfMemoryError\n",
    "    if i!=0 and i%5==0:\n",
    "        pickle.dump(data_vid_rep, open('out' + str(i) + '.p','wb'))\n",
    "        del data_vid_rep\n",
    "    \n",
    "    print('...forwarding frame ' + str(i) + '...')\n",
    "    \n",
    "    #next batch\n",
    "    batch, _ = batchloader.__next__()\n",
    "    \n",
    "    #cast to variable\n",
    "    batch_var = Variable(batch)\n",
    "    \n",
    "    #Check whether cua is available and utilize if possible\n",
    "    if torch.cuda.is_available():\n",
    "        batch_var = batch_var.cuda()\n",
    "    \n",
    "    #output of CNN\n",
    "    xout = pretrained_model(batch_var)\n",
    "    \n",
    "    #apply pooling strategy.\n",
    "    #here we use simple average pooling\n",
    "    xout = VP.average_pooling(xout)\n",
    "    \n",
    "    #store the output in data_vid_rep\n",
    "    if i == 0 or i%5==0:\n",
    "        data_vid_rep = xout\n",
    "        data_vid_rep = data_vid_rep.view(1,data_vid_rep.size()[0])\n",
    "    else:\n",
    "        data_vid_rep = torch.cat((data_vid_rep, xout.view(1,xout.size()[0])),0) \n",
    "        \n",
    "    del xout\n",
    "\n",
    "#store the output of the last iteration in a pickle file\n",
    "pickle.dump(data_vid_rep, open('out' + str(N) + '.p','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load CNN output and merge the above produced output into a single tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = data['targets'].shape[0]\n",
    "\n",
    "for i in range(0,N+1):\n",
    "    if i!=0 and (i%5==0 or i==N):\n",
    "        print('...loading frames ' + str(i) + '...')\n",
    "        temp = pickle.load(open('out' + str(i) + '.p','rb'))\n",
    "        if i==5:\n",
    "            print(temp.shape)\n",
    "            conv_out = temp\n",
    "        else:\n",
    "            conv_out = torch.cat((conv_out, temp),0) \n",
    "            print(conv_out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dump into pickle file for later usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(conv_out.cpu().data.numpy(),open('conv_out_56_all.p','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the output of the CNN from a pickle file and split the training and the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load form pickle\n",
    "conv_out = pickle.load(open('conv_out_56_all.p','rb'))\n",
    "\n",
    "#number training example\n",
    "N = conv_out.shape[0]\n",
    "\n",
    "#separate validation from training set\n",
    "idx_val = np.random.choice(np.arange(0,N), size=int(N/8), replace=False)\n",
    "val_data = conv_out[idx_val]\n",
    "val_targets = data['targets'][idx_val]\n",
    "train_data = np.delete(conv_out, idx_val, axis=0)\n",
    "train_targets = np.delete(data['targets'], idx_val, axis=0)\n",
    "\n",
    "#store training and validation data in TensorDataset object\n",
    "train_dataset = TensorDataset(torch.from_numpy(train_data),torch.from_numpy(train_targets))\n",
    "val_dataset = TensorDataset(torch.from_numpy(val_data),torch.from_numpy(val_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train a classifier on the pooled output of the CNN to predict the genre of the video game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining hyperparameters\n",
    "epochs = 200\n",
    "learning_rate = 0.01\n",
    "output_classes = 2\n",
    "\n",
    "# define the network that is being used for prediction\n",
    "pred_head = PH.ThreeLayerFCN([conv_out.shape[1],int(conv_out.shape[1]/2),output_classes])\n",
    "\n",
    "#Check whether cua is available and utilize if possible\n",
    "if torch.cuda.is_available():\n",
    "    pred_head.cuda()\n",
    "\n",
    "# Get a dataloader for training and validation data    \n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1)\n",
    "\n",
    "# Used optimization method + its parameters\n",
    "optimizer = torch.optim.SGD(pred_head.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "# store the history of the learning process\n",
    "loss_history = []\n",
    "pred_scores_history = []\n",
    "\n",
    "#iterate over epochs\n",
    "for i in range(1,epochs):\n",
    "    \n",
    "    #iterate over batches\n",
    "    for j, (inputs, targets) in enumerate(train_dataloader):\n",
    "        \n",
    "        #cast to variable\n",
    "        inputs = Variable(inputs)\n",
    "        targets = Variable(targets)\n",
    "        \n",
    "        #Check whether cua is available and utilize if possible\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "        \n",
    "        # Zero the gradients of the model parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Compute the output of the model\n",
    "        outputs = pred_head(inputs)\n",
    "        \n",
    "        # Used loss function\n",
    "        loss_func=torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Compute loss with respect to the targets\n",
    "        loss = loss_func(outputs,targets)\n",
    "        \n",
    "        # compute gradients of parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_history.append(loss)\n",
    "   \n",
    "    # iterate over validation set and and  \n",
    "    pred_scores = []\n",
    "    for i, (inputs, targets) in enumerate(val_dataloader):\n",
    "        inputs = Variable(inputs)\n",
    "        targets = Variable(targets)\n",
    "        \n",
    "        #Check whether cua is available and utilize if possible\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "        \n",
    "        outputs = pred_head(inputs)\n",
    "        \n",
    "        # get the predition -> index of maximum of the output\n",
    "        _, preds = torch.max(outputs,1)\n",
    "\n",
    "        # zero for wrong and 1 for correct calissification\n",
    "        scores = (preds.cpu() == targets.cpu()).data.numpy()\n",
    "\n",
    "        pred_scores.append(scores)\n",
    "\n",
    "    # store the accuracy for each epoch\n",
    "    pred_scores_history.append(np.mean(pred_scores))\n",
    "    print(np.mean(pred_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy on validation set depending on the amounts of epochs\n",
    "plt.plot(pred_scores_history)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
